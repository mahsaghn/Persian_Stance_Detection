[2021-09-24 15:14:39,741][root][INFO] - hazm tokenizer
[2021-09-24 15:15:12,139][tensorflow][WARNING] - The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).
[2021-09-24 15:15:13,112][tensorflow][WARNING] - The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
[2021-09-24 15:15:16,085][root][INFO] - Model Summary:
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_ids (InputLayer)          [(None, 32)]         0                                            
__________________________________________________________________________________________________
attention_mask (InputLayer)     [(None, 32)]         0                                            
__________________________________________________________________________________________________
token_type_ids (InputLayer)     [(None, 32)]         0                                            
__________________________________________________________________________________________________
tf_bert_model (TFBertModel)     TFBaseModelOutputWit 162841344   input_ids[0][0]                  
                                                                 attention_mask[0][0]             
                                                                 token_type_ids[0][0]             
__________________________________________________________________________________________________
tf.math.reduce_mean (TFOpLambda (None, 768)          0           tf_bert_model[0][0]              
__________________________________________________________________________________________________
dense (Dense)                   (None, 32)           24608       tf.math.reduce_mean[0][0]        
__________________________________________________________________________________________________
dropout_37 (Dropout)            (None, 32)           0           dense[0][0]                      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 16)           528         dropout_37[0][0]                 
__________________________________________________________________________________________________
classifier (Dense)              (None, 4)            68          dense_1[0][0]                    
==================================================================================================
Total params: 162,866,548
Trainable params: 162,866,548
Non-trainable params: 0
__________________________________________________________________________________________________
[2021-09-24 15:15:16,202][tensorflow][WARNING] - The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).
[2021-09-24 15:15:16,254][tensorflow][WARNING] - The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
[2021-09-24 15:15:21,301][tensorflow][WARNING] - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.
[2021-09-24 15:15:22,293][tensorflow][WARNING] - AutoGraph could not transform <function get_f1 at 0x7fae8dc99170> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Unable to locate the source code of <function get_f1 at 0x7fae8dc99170>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[2021-09-24 15:15:23,563][tensorflow][WARNING] - The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).
[2021-09-24 15:15:23,614][tensorflow][WARNING] - The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
[2021-09-24 15:15:28,610][tensorflow][WARNING] - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.
[2021-09-24 15:15:59,198][tensorflow][WARNING] - The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).
[2021-09-24 15:15:59,251][tensorflow][WARNING] - The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
[2021-09-24 15:16:07,310][root][INFO] - Epoch: 0, loss: 1.286707, accuracy: 0.384578, precision: 0.537549, recall: 0.065542, get_f1: 0.117669, val_loss: 1.035095, val_accuracy: 0.595376, val_precision: 0.741935, val_recall: 0.310212, val_get_f1: 0.351871
[2021-09-24 15:16:36,746][root][INFO] - Epoch: 1, loss: 1.059327, accuracy: 0.535904, precision: 0.710175, recall: 0.333012, get_f1: 0.460325, val_loss: 0.797702, val_accuracy: 0.701349, val_precision: 0.834667, val_recall: 0.603083, val_get_f1: 0.635948
[2021-09-24 15:17:06,171][root][INFO] - Epoch: 2, loss: 0.886190, accuracy: 0.629398, precision: 0.784476, recall: 0.457831, get_f1: 0.577716, val_loss: 0.688336, val_accuracy: 0.749518, val_precision: 0.828851, val_recall: 0.653179, val_get_f1: 0.705388
[2021-09-24 15:17:35,602][root][INFO] - Epoch: 3, loss: 0.786573, accuracy: 0.685783, precision: 0.822502, recall: 0.567229, get_f1: 0.674525, val_loss: 0.639411, val_accuracy: 0.770713, val_precision: 0.823400, val_recall: 0.718690, val_get_f1: 0.716376
[2021-09-24 15:18:02,639][root][INFO] - Epoch: 4, loss: 0.681230, accuracy: 0.753253, precision: 0.862264, recall: 0.660723, get_f1: 0.747335, val_loss: 0.708990, val_accuracy: 0.743738, val_precision: 0.792123, val_recall: 0.697495, val_get_f1: 0.717675
[2021-09-24 15:18:32,080][root][INFO] - Epoch: 5, loss: 0.577210, accuracy: 0.783614, precision: 0.884798, recall: 0.718072, get_f1: 0.792958, val_loss: 0.637749, val_accuracy: 0.780347, val_precision: 0.811594, val_recall: 0.755299, val_get_f1: 0.750550
[2021-09-24 15:18:59,108][root][INFO] - Epoch: 6, loss: 0.470469, accuracy: 0.817831, precision: 0.916715, recall: 0.769157, get_f1: 0.832607, val_loss: 0.760981, val_accuracy: 0.780347, val_precision: 0.800403, val_recall: 0.764933, val_get_f1: 0.728576
[2021-09-24 15:19:28,484][root][INFO] - Epoch: 7, loss: 0.402294, accuracy: 0.851566, precision: 0.919434, recall: 0.813976, get_f1: 0.862243, val_loss: 0.776308, val_accuracy: 0.784200, val_precision: 0.802020, val_recall: 0.764933, val_get_f1: 0.769798
[2021-09-24 15:19:57,943][root][INFO] - Epoch: 8, loss: 0.364194, accuracy: 0.863133, precision: 0.932868, recall: 0.837108, get_f1: 0.877283, val_loss: 0.793713, val_accuracy: 0.803468, val_precision: 0.815416, val_recall: 0.774566, val_get_f1: 0.789538
[2021-09-24 15:20:25,049][root][INFO] - Epoch: 9, loss: 0.334325, accuracy: 0.875663, precision: 0.938172, recall: 0.840964, get_f1: 0.883822, val_loss: 0.936353, val_accuracy: 0.799615, val_precision: 0.802348, val_recall: 0.789981, val_get_f1: 0.807649
[2021-09-24 15:20:52,058][root][INFO] - Epoch: 10, loss: 0.312263, accuracy: 0.880000, precision: 0.952941, recall: 0.858795, get_f1: 0.905071, val_loss: 0.838038, val_accuracy: 0.803468, val_precision: 0.824000, val_recall: 0.793834, val_get_f1: 0.781472
[2021-09-24 15:21:19,095][root][INFO] - Epoch: 11, loss: 0.325654, accuracy: 0.883373, precision: 0.949143, recall: 0.854458, get_f1: 0.900227, val_loss: 0.964033, val_accuracy: 0.801541, val_precision: 0.813765, val_recall: 0.774566, val_get_f1: 0.759821
[2021-09-24 15:21:46,154][root][INFO] - Epoch: 12, loss: 0.298077, accuracy: 0.884819, precision: 0.948827, recall: 0.857831, get_f1: 0.898674, val_loss: 0.915416, val_accuracy: 0.789981, val_precision: 0.810484, val_recall: 0.774566, val_get_f1: 0.787887
[2021-09-24 15:22:15,368][root][INFO] - Epoch: 13, loss: 0.266813, accuracy: 0.889639, precision: 0.949682, recall: 0.864096, get_f1: 0.904821, val_loss: 0.912888, val_accuracy: 0.811175, val_precision: 0.822835, val_recall: 0.805395, val_get_f1: 0.794837
[2021-09-24 15:22:42,380][root][INFO] - Epoch: 14, loss: 0.248146, accuracy: 0.900723, precision: 0.968984, recall: 0.873253, get_f1: 0.918748, val_loss: 1.223384, val_accuracy: 0.784200, val_precision: 0.791667, val_recall: 0.768786, val_get_f1: 0.748813
[2021-09-24 15:23:09,453][root][INFO] - Epoch: 15, loss: 0.210620, accuracy: 0.912771, precision: 0.968636, recall: 0.893012, get_f1: 0.928719, val_loss: 1.119023, val_accuracy: 0.784200, val_precision: 0.785575, val_recall: 0.776493, val_get_f1: 0.741308
[2021-09-24 15:23:36,497][root][INFO] - Epoch: 16, loss: 0.195034, accuracy: 0.920482, precision: 0.972973, recall: 0.902169, get_f1: 0.934462, val_loss: 1.390324, val_accuracy: 0.788054, val_precision: 0.802372, val_recall: 0.782274, val_get_f1: 0.768233
[2021-09-24 15:24:03,500][root][INFO] - Epoch: 17, loss: 0.211254, accuracy: 0.921446, precision: 0.977987, recall: 0.899277, get_f1: 0.938849, val_loss: 1.321424, val_accuracy: 0.772640, val_precision: 0.776265, val_recall: 0.768786, val_get_f1: 0.788522
[2021-09-24 15:24:30,499][root][INFO] - Epoch: 18, loss: 0.227661, accuracy: 0.903133, precision: 0.963760, recall: 0.884337, get_f1: 0.920090, val_loss: 1.100462, val_accuracy: 0.803468, val_precision: 0.808594, val_recall: 0.797688, val_get_f1: 0.759214
